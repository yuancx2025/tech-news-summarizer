# LLM-Powered Tech News Summarizer ğŸš€ğŸ“°

This project builds a full-stack pipeline to scrape, clean, summarize, and visualize tech news using large language models like BART and T5.

## ğŸš€ Quick Start

### Installation

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd tech-news-summarizer
   ```

2. **Create and activate virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Installation complete!** The TextRank summarizer now uses a custom sentence tokenizer that doesn't require additional downloads.

## ğŸ§ª Running Evaluations

After installation, you can evaluate different summarization models:

### Basic Evaluation (Qualitative)
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --run-name qual_check \
  --models lead3,textrank,distilbart,bart \
  --limit 100
```

### Fast Evaluation (Skip HF Models)
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --run-name fast_check \
  --models lead3,textrank \
  --fast \
  --limit 100
```

### Evaluation with References
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --ref-field summary \
  --run-name with_refs \
  --models lead3,textrank,distilbart,bart \
  --limit 100
```

### Available Models
- **lead3**: Lead-3 sentences (baseline) - âš¡ Very fast
- **textrank**: TextRank algorithm (custom sentence tokenizer) - âš¡ Fast
- **distilbart**: DistilBART-CNN model - ğŸŒ Slow (first run downloads model)
- **bart**: BART-Large-CNN model - ğŸŒ Slow (first run downloads model)

**Note**: HF models (distilbart, bart) are slow on first run due to model downloading. Use `--fast` flag to skip them for quick evaluation.

Results will be saved to `results/<run_name>/` directory.

## ğŸ“Œ Project Goals
- Scrape tech news from sources like TechCrunch, Wired, and The Verge
- Summarize using pretrained LLMs (Hugging Face Transformers)
- Analyze article trends and summary performance
- Deploy via Streamlit with interactive UI
- Visualize insights using Tableau

## ğŸ—‚ï¸ Project Structure
```text
tech-news-summarizer/
â”œâ”€â”€ ğŸ“ config/                    # Configuration files
â”‚   â”œâ”€â”€ feeds.yml                 # News source configurations
â”‚   â””â”€â”€ feeds_finance.yml         # Finance-specific feeds
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Data storage and processing
â”‚   â”œâ”€â”€ raw/                      # Raw scraped articles
â”‚   â”‚   â”œâ”€â”€ articles.jsonl
â”‚   â”‚   â””â”€â”€ articles_2025-08-16.jsonl
â”‚   â””â”€â”€ processed/                # Cleaned and processed data
â”‚       â”œâ”€â”€ articles_clean.csv
â”‚       â”œâ”€â”€ articles_clean.jsonl
â”‚       â”œâ”€â”€ preprocessed_2025-08-19.jsonl
â”‚       â””â”€â”€ preprocessed_2025-08-19_manifest.json
â”‚
â”œâ”€â”€ ğŸ“ model/                     # AI/ML model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluate.py               # Model evaluation framework
â”‚   â”œâ”€â”€ metrics.py                # Evaluation metrics (ROUGE, BLEU, etc.)
â”‚   â”œâ”€â”€ rag_summarizer.py         # RAG-based summarization system
â”‚   â””â”€â”€ summarizers.py            # Multiple summarization models
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ eda_articles.py          # Article data exploration
â”‚   â”œâ”€â”€ eda_preprocess.py        # Preprocessing analysis
â”‚   â””â”€â”€ eda.ipynb                # Main exploratory analysis
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   # Automation and utility scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bootstrap.py              # Project setup and initialization
â”‚   â”œâ”€â”€ build_embeddings.py       # Generate article embeddings
â”‚   â”œâ”€â”€ build_faiss_index.py      # Build FAISS vector search index
â”‚   â”œâ”€â”€ clean_export_preprocess.py # Data cleaning pipeline
â”‚   â”œâ”€â”€ eval_rag_vs_vanilla.py    # RAG vs. standard summarization comparison
â”‚   â”œâ”€â”€ rag_batch.py              # Batch RAG processing
â”‚   â”œâ”€â”€ run_full_scrape.sh        # Full scraping automation script
â”‚   â””â”€â”€ scrape_newspaper.py       # News article scraper
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Core source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaning.py               # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ embeddings.py             # Text embedding generation
â”‚   â”œâ”€â”€ faiss_store.py            # FAISS vector database operations
â”‚   â””â”€â”€ schema.py                 # Data schemas and validation
â”‚
â”œâ”€â”€ ğŸ“ tests/                     # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_clean_export_preprocess.py
â”‚   â”œâ”€â”€ test_cleaning.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_end_to_end_smoke.py
â”‚   â”œâ”€â”€ test_faiss_store.py
â”‚   â”œâ”€â”€ test_inference.py
â”‚   â”œâ”€â”€ test_metrics.py
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â””â”€â”€ test_schema.py
â”‚
â”œâ”€â”€ ğŸ“ venv/                      # Python virtual environment
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ setup.py                      # Package installation configuration
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md

```

## ğŸš§ Project Milestones

| Week | Milestone |
|------|-----------|
| âœ… Week 1 | Scraped and cleaned tech articles |
| âœ… Week 2 | Built and evaluated LLM summarizer |
| âœ… Week 3 | RAG-based improvement with FAISS |
| âœ… Week 4 | RAG-based recommendation |
| âœ… Week 5 | Streamlit app deployment + demo |

