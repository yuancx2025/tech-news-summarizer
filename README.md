# LLM-Powered Tech News Summarizer ğŸš€ğŸ“°

This project builds a full-stack pipeline to scrape, clean, summarize, and visualize tech news using large language models like BART and T5.

## ğŸš€ Quick Start

### Installation

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd tech-news-summarizer
   ```

2. **Create and activate virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Installation complete!** The TextRank summarizer now uses a custom sentence tokenizer that doesn't require additional downloads.

### Alternative Installation with setup.py

You can also install using the setup script which will automatically download NLTK data:

```bash
pip install -e .
```

## ğŸ§ª Running Evaluations

After installation, you can evaluate different summarization models:

### Basic Evaluation (Qualitative)
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --run-name qual_check \
  --models lead3,textrank,distilbart,bart \
  --limit 100
```

### Fast Evaluation (Skip HF Models)
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --run-name fast_check \
  --models lead3,textrank \
  --fast \
  --limit 100
```

### Evaluation with References
```bash
python -m model.evaluate \
  --pre-jsonl data/processed/preprocessed_2025-08-19.jsonl \
  --ref-field summary \
  --run-name with_refs \
  --models lead3,textrank,distilbart,bart \
  --limit 100
```

### Available Models
- **lead3**: Lead-3 sentences (baseline) - âš¡ Very fast
- **textrank**: TextRank algorithm (custom sentence tokenizer) - âš¡ Fast
- **distilbart**: DistilBART-CNN model - ğŸŒ Slow (first run downloads model)
- **bart**: BART-Large-CNN model - ğŸŒ Slow (first run downloads model)

**Note**: HF models (distilbart, bart) are slow on first run due to model downloading. Use `--fast` flag to skip them for quick evaluation.

Results will be saved to `results/<run_name>/` directory.

## ğŸ“Œ Project Goals
- Scrape tech news from sources like TechCrunch, Wired, and The Verge
- Summarize using pretrained LLMs (Hugging Face Transformers)
- Analyze article trends and summary performance
- Deploy via Streamlit with interactive UI
- Visualize insights using Tableau

## ğŸ—‚ï¸ Project Structure
```text
llm-tech-news-summarizer/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # raw scraped data (unprocessed)
â”‚   â”‚   â””â”€â”€ articles.jsonl
â”‚   â”œâ”€â”€ processed/            # cleaned & standardized data
â”‚   â”‚   â”œâ”€â”€ articles_clean.csv
â”‚   â”‚   â””â”€â”€ news.sqlite
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scrape_newspaper.py   # scrape news articles
â”‚   â”œâ”€â”€ io_raw.py             # helper functions to save raw data
â”‚   â”œâ”€â”€ sqlite_raw.py         # store raw data in SQLite
â”‚   â”œâ”€â”€ cleaner.py            # clean & filter raw data â†’ processed
â”‚   â””â”€â”€ ...                   # future utils, e.g., summarizer helpers
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ summarizers.py        # summarization models (Lead-3, TextRank, BART, etc.)
â”‚   â”œâ”€â”€ evaluate.py           # evaluation script for comparing models
â”‚   â””â”€â”€ test_inference.py     # quick tests for summarizer
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb              # exploratory data analysis
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ app/                      # Streamlit or Gradio front-end
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ feeds.yml             # list of sources/domains to scrape
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

```

## ğŸš§ Project Milestones

| Week | Milestone |
|------|-----------|
| âœ… Week 1 | Scraped and cleaned tech articles |
| ğŸ”„ Week 2 | Built and evaluated LLM summarizer |
| â³ Week 3 | RAG-based improvement with FAISS |
| â³ Week 4 | Tableau visualizations of trends |
| â³ Week 5 | Streamlit app deployment + demo |

