# Embeddings (Gemini)
embedding_model: models/text-embedding-004  # Gemini embedding model

# LLM for summarization & reasoning
llm_model: gemini-2.5-flash  # Gemini 2.5 Flash
llm_provider: gemini  # "gemini" or "openai"

# Chroma persistence
chroma_dir: data/vdb/chroma

# Chunking
chunk_size: 900          # 700–1000 chars is ideal for news
chunk_overlap: 120       # ~10–15%
min_chars: 380           # skip tiny bodies
separators: ["\n\n", "\n", ". ", "? ", "! ", " ", ""]

# Ingestion batching
batch_limit: 1500        # number of chunks per persist

# Retrieval defaults (Step 2)
retrieval:
  k_final: 8
  fetch_k: 60
  lambda_mult: 0.6
  language: en
  days_back_start: 60
  days_back_max: 365
